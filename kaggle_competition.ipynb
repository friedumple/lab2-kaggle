{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fab584e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-09T00:43:51.938351Z",
     "iopub.status.busy": "2024-12-09T00:43:51.937962Z",
     "iopub.status.idle": "2024-12-09T00:44:31.490953Z",
     "shell.execute_reply": "2024-12-09T00:44:31.489687Z"
    },
    "papermill": {
     "duration": 39.56235,
     "end_time": "2024-12-09T00:44:31.495735",
     "exception": false,
     "start_time": "2024-12-09T00:43:51.933385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _score          _index                                            _source  \\\n",
      "0     391  hashtag_tweets  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...   \n",
      "1     433  hashtag_tweets  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...   \n",
      "2     232  hashtag_tweets  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...   \n",
      "3     376  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...   \n",
      "4     989  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...   \n",
      "\n",
      "            _crawldate   _type  \n",
      "0  2015-05-23 11:42:47  tweets  \n",
      "1  2016-01-28 04:52:09  tweets  \n",
      "2  2017-12-25 04:39:20  tweets  \n",
      "3  2016-01-24 23:53:05  tweets  \n",
      "4  2016-01-08 17:18:59  tweets  \n",
      "   tweet_id       emotion\n",
      "0  0x3140b1       sadness\n",
      "1  0x368b73       disgust\n",
      "2  0x296183  anticipation\n",
      "3  0x2bd6e1           joy\n",
      "4  0x2ee1dd  anticipation\n",
      "   tweet_id identification\n",
      "0  0x28cc61           test\n",
      "1  0x29e452          train\n",
      "2  0x2b3819          train\n",
      "3  0x2db41f           test\n",
      "4  0x2a2acc          train\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 讀取數據\n",
    "tweets = pd.read_json('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', lines=True)\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv')\n",
    "data_id = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv')\n",
    "\n",
    "# 檢查數據\n",
    "print(tweets.head())\n",
    "print(emotion.head())\n",
    "print(data_id.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "835ca688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:44:31.503020Z",
     "iopub.status.busy": "2024-12-09T00:44:31.502649Z",
     "iopub.status.idle": "2024-12-09T00:44:35.770297Z",
     "shell.execute_reply": "2024-12-09T00:44:35.769067Z"
    },
    "papermill": {
     "duration": 4.274577,
     "end_time": "2024-12-09T00:44:35.773168",
     "exception": false,
     "start_time": "2024-12-09T00:44:31.498591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in tweets: Index(['_score', '_index', '_source', '_crawldate', '_type'], dtype='object')\n",
      "Columns in emotion: Index(['tweet_id', 'emotion'], dtype='object')\n",
      "Columns in data_id: Index(['tweet_id', 'identification'], dtype='object')\n",
      "   tweet_id       emotion\n",
      "0  0x3140b1       sadness\n",
      "1  0x368b73       disgust\n",
      "2  0x296183  anticipation\n",
      "3  0x2bd6e1           joy\n",
      "4  0x2ee1dd  anticipation\n",
      "   tweet_id identification\n",
      "0  0x28cc61           test\n",
      "1  0x29e452          train\n",
      "2  0x2b3819          train\n",
      "3  0x2db41f           test\n",
      "4  0x2a2acc          train\n"
     ]
    }
   ],
   "source": [
    "# 檢查 tweets 的列\n",
    "print(\"Columns in tweets:\", tweets.columns)\n",
    "\n",
    "# 檢查 emotion 的列\n",
    "print(\"Columns in emotion:\", emotion.columns)\n",
    "\n",
    "# 檢查 data_id 的列\n",
    "print(\"Columns in data_id:\", data_id.columns)\n",
    "\n",
    "# 確保所有表的 'tweet_id' 列名一致\n",
    "tweets.rename(columns=lambda x: x.strip(), inplace=True)  # 去除空格\n",
    "emotion.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data_id.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "# 如果有具體列名錯誤，例如 'Tweet_ID' 或 'tweetId'\n",
    "tweets.rename(columns={'Tweet_ID': 'tweet_id'}, inplace=True)\n",
    "emotion.rename(columns={'Tweet_ID': 'tweet_id'}, inplace=True)\n",
    "data_id.rename(columns={'Tweet_ID': 'tweet_id'}, inplace=True)\n",
    "\n",
    "# 檢查文件頭部是否正確\n",
    "print(pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv').head())\n",
    "print(pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv').head())\n",
    "\n",
    "# 確保文件讀取時正確處理編碼\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv', encoding='utf-8')\n",
    "data_id = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80cd470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:44:35.780817Z",
     "iopub.status.busy": "2024-12-09T00:44:35.780465Z",
     "iopub.status.idle": "2024-12-09T00:45:46.544716Z",
     "shell.execute_reply": "2024-12-09T00:45:46.543638Z"
    },
    "papermill": {
     "duration": 70.770981,
     "end_time": "2024-12-09T00:45:46.547238",
     "exception": false,
     "start_time": "2024-12-09T00:44:35.776257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_score': 391, '_index': 'hashtag_tweets', '_source': {'tweet': {'hashtags': ['Snapchat'], 'tweet_id': '0x376b20', 'text': 'People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that\\'s <LH>'}}, '_crawldate': '2015-05-23 11:42:47', '_type': 'tweets'}\n",
      "{'_score': 433, '_index': 'hashtag_tweets', '_source': {'tweet': {'hashtags': ['freepress', 'TrumpLegacy', 'CNN'], 'tweet_id': '0x2d5350', 'text': '@brianklaas As we see, Trump is dangerous to #freepress around the world. What a <LH> <LH> #TrumpLegacy.  #CNN'}}, '_crawldate': '2016-01-28 04:52:09', '_type': 'tweets'}\n",
      "{'_score': 232, '_index': 'hashtag_tweets', '_source': {'tweet': {'hashtags': ['bibleverse'], 'tweet_id': '0x28b412', 'text': 'Confident of your obedience, I write to you, knowing that you will do even more than I ask. (Philemon 1:21) 3/4 #bibleverse <LH> <LH>'}}, '_crawldate': '2017-12-25 04:39:20', '_type': 'tweets'}\n",
      "{'_score': 376, '_index': 'hashtag_tweets', '_source': {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5b0', 'text': 'Now ISSA is stalking Tasha 😂😂😂 <LH>'}}, '_crawldate': '2016-01-24 23:53:05', '_type': 'tweets'}\n",
      "{'_score': 989, '_index': 'hashtag_tweets', '_source': {'tweet': {'hashtags': [], 'tweet_id': '0x2de201', 'text': '\"Trust is not the same as faith. A friend is someone you trust. Putting faith in anyone is a mistake.\" ~ Christopher Hitchens <LH> <LH>'}}, '_crawldate': '2016-01-08 17:18:59', '_type': 'tweets'}\n",
      "Flattened tweets data preview:\n",
      "                  tweet.hashtags tweet.tweet_id  \\\n",
      "0                     [Snapchat]       0x376b20   \n",
      "1  [freepress, TrumpLegacy, CNN]       0x2d5350   \n",
      "2                   [bibleverse]       0x28b412   \n",
      "3                             []       0x1cd5b0   \n",
      "4                             []       0x2de201   \n",
      "\n",
      "                                          tweet.text  \n",
      "0  People who post \"add me on #Snapchat\" must be ...  \n",
      "1  @brianklaas As we see, Trump is dangerous to #...  \n",
      "2  Confident of your obedience, I write to you, k...  \n",
      "3                Now ISSA is stalking Tasha 😂😂😂 <LH>  \n",
      "4  \"Trust is not the same as faith. A friend is s...  \n",
      "Merged data preview:\n",
      "                  tweet.hashtags  tweet_id  \\\n",
      "0                     [Snapchat]  0x376b20   \n",
      "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
      "2                   [bibleverse]  0x28b412   \n",
      "3                             []  0x1cd5b0   \n",
      "4                             []  0x2de201   \n",
      "\n",
      "                                          tweet_text       emotion  \\\n",
      "0  People who post \"add me on #Snapchat\" must be ...  anticipation   \n",
      "1  @brianklaas As we see, Trump is dangerous to #...       sadness   \n",
      "2  Confident of your obedience, I write to you, k...           NaN   \n",
      "3                Now ISSA is stalking Tasha 😂😂😂 <LH>          fear   \n",
      "4  \"Trust is not the same as faith. A friend is s...           NaN   \n",
      "\n",
      "  identification  \n",
      "0          train  \n",
      "1          train  \n",
      "2           test  \n",
      "3          train  \n",
      "4           test  \n"
     ]
    }
   ],
   "source": [
    "# 匯入必要套件\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 讀取 JSON 檔案並檢查結構\n",
    "tweets = []\n",
    "with open('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i < 5:  # 檢查前 5 行的 JSON 結構\n",
    "            print(json.loads(line))  # 打印 JSON 結構\n",
    "        tweets.append(json.loads(line))\n",
    "\n",
    "# 將 JSON 資料轉為 DataFrame\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "\n",
    "# 提取 `_source` 中的 `tweet` 資料\n",
    "tweets_df = pd.json_normalize(tweets_df['_source'])\n",
    "\n",
    "# 檢查展平後的資料\n",
    "print(\"Flattened tweets data preview:\")\n",
    "print(tweets_df.head())\n",
    "\n",
    "# 重命名列以匹配其他表格\n",
    "tweets_df.rename(columns={'tweet.tweet_id': 'tweet_id', 'tweet.text': 'tweet_text'}, inplace=True)\n",
    "\n",
    "# 讀取其他資料表\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv', encoding='utf-8')\n",
    "data_id = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv', encoding='utf-8')\n",
    "\n",
    "# 檢查欄位名稱並去除多餘空格\n",
    "tweets_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "emotion.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data_id.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "# 合併資料\n",
    "tweets_df = tweets_df.merge(emotion, on='tweet_id', how='left')  # 合併情緒標籤\n",
    "tweets_df = tweets_df.merge(data_id, on='tweet_id', how='left')  # 合併數據識別\n",
    "\n",
    "# 確認結果\n",
    "print(\"Merged data preview:\")\n",
    "print(tweets_df.head())\n",
    "\n",
    "# 儲存結果到 CSV（可選）\n",
    "tweets_df.to_csv('merged_tweets.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142bd393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:45:46.555383Z",
     "iopub.status.busy": "2024-12-09T00:45:46.554969Z",
     "iopub.status.idle": "2024-12-09T00:47:09.824369Z",
     "shell.execute_reply": "2024-12-09T00:47:09.823163Z"
    },
    "papermill": {
     "duration": 83.276292,
     "end_time": "2024-12-09T00:47:09.826829",
     "exception": false,
     "start_time": "2024-12-09T00:45:46.550537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Columns: Index(['tweet.hashtags', 'tweet_id', 'tweet_text'], dtype='object')\n",
      "Training Data:                   tweet.hashtags  tweet_id  \\\n",
      "0                     [Snapchat]  0x376b20   \n",
      "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
      "3                             []  0x1cd5b0   \n",
      "5      [authentic, LaughOutLoud]  0x1d755c   \n",
      "6                             []  0x2c91a8   \n",
      "\n",
      "                                          tweet_text  \\\n",
      "0  People who post \"add me on #Snapchat\" must be ...   \n",
      "1  @brianklaas As we see, Trump is dangerous to #...   \n",
      "3                Now ISSA is stalking Tasha 😂😂😂 <LH>   \n",
      "5  @RISKshow @TheKevinAllison Thx for the BEST TI...   \n",
      "6       Still waiting on those supplies Liscus. <LH>   \n",
      "\n",
      "                                          clean_text       emotion  \\\n",
      "0   people post add must dehydrated cuz man thats lh  anticipation   \n",
      "1             see trump dangerous around world lh lh       sadness   \n",
      "3                             issa stalking tasha lh          fear   \n",
      "5  thx best time tonight stories heartbreakingly ...           joy   \n",
      "6                   still waiting supplies liscus lh  anticipation   \n",
      "\n",
      "  identification  \n",
      "0          train  \n",
      "1          train  \n",
      "3          train  \n",
      "5          train  \n",
      "6          train  \n",
      "Test Data:                        tweet.hashtags  tweet_id  \\\n",
      "2                        [bibleverse]  0x28b412   \n",
      "4                                  []  0x2de201   \n",
      "9   [materialism, money, possessions]  0x218443   \n",
      "30               [GodsPlan, GodsWork]  0x2939d5   \n",
      "33                                 []  0x26289a   \n",
      "\n",
      "                                           tweet_text  \\\n",
      "2   Confident of your obedience, I write to you, k...   \n",
      "4   \"Trust is not the same as faith. A friend is s...   \n",
      "9   When do you have enough ? When are you satisfi...   \n",
      "30  God woke you up, now chase the day #GodsPlan #...   \n",
      "33  In these tough times, who do YOU turn to as yo...   \n",
      "\n",
      "                                           clean_text emotion identification  \n",
      "2   confident obedience write knowing even ask phi...     NaN           test  \n",
      "4   trust faith friend someone trust putting faith...     NaN           test  \n",
      "9               enough satisfied goal really money lh     NaN           test  \n",
      "30                              god woke chase day lh     NaN           test  \n",
      "33                    tough times turn symbol hope lh     NaN           test  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# 確保下載 nltk 停用詞（如果無法在線下載，提供手動路徑）\n",
    "try:\n",
    "    nltk.download('stopwords')\n",
    "except:\n",
    "    print(\"Unable to download stopwords. Please check the network connection.\")\n",
    "\n",
    "# 如果網路不可用，手動提供停用詞\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except:\n",
    "    stop_words = {\"a\", \"an\", \"the\", \"is\", \"in\", \"at\", \"of\", \"on\", \"and\", \"to\", \"with\", \"for\", \"by\", \"that\", \"this\", \"from\"}\n",
    "\n",
    "# 確保 `tweets` 是 DataFrame\n",
    "tweets_list = []  # 如果原本是 list, 應先構造 DataFrame\n",
    "with open('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        tweets_list.append(json.loads(line))\n",
    "\n",
    "# 將 JSON list 轉為 DataFrame\n",
    "tweets_df = pd.json_normalize([tweet['_source'] for tweet in tweets_list])\n",
    "\n",
    "# 提取欄位\n",
    "tweets_df.rename(columns={'tweet.text': 'tweet_text', 'tweet.tweet_id': 'tweet_id'}, inplace=True)\n",
    "\n",
    "# 確認欄位\n",
    "print(\"Columns:\", tweets_df.columns)\n",
    "\n",
    "# 預處理函數\n",
    "def preprocess_text(text):\n",
    "    # 刪除網址、標籤和特殊字符\n",
    "    text = re.sub(r'http\\S+|www\\S+|@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()  # 全部轉小寫\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # 移除停用詞\n",
    "    return text\n",
    "\n",
    "# 預處理文本\n",
    "tweets_df['clean_text'] = tweets_df['tweet_text'].apply(preprocess_text)\n",
    "\n",
    "# 加載其他表格\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv', encoding='utf-8')\n",
    "data_id = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv', encoding='utf-8')\n",
    "\n",
    "# 合併數據\n",
    "tweets_df = tweets_df.merge(emotion, on='tweet_id', how='left')\n",
    "tweets_df = tweets_df.merge(data_id, on='tweet_id', how='left')\n",
    "\n",
    "# 分割訓練和測試數據\n",
    "train_data = tweets_df[tweets_df['identification'] == 'train']\n",
    "test_data = tweets_df[tweets_df['identification'] == 'test']\n",
    "\n",
    "X_train = train_data['clean_text']\n",
    "y_train = train_data['emotion']\n",
    "X_test = test_data['clean_text']\n",
    "\n",
    "# 確認分割後數據\n",
    "print(\"Training Data:\", train_data.head())\n",
    "print(\"Test Data:\", test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c755c401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:47:09.835482Z",
     "iopub.status.busy": "2024-12-09T00:47:09.835047Z",
     "iopub.status.idle": "2024-12-09T00:47:28.644602Z",
     "shell.execute_reply": "2024-12-09T00:47:28.643471Z"
    },
    "papermill": {
     "duration": 18.816719,
     "end_time": "2024-12-09T00:47:28.647073",
     "exception": false,
     "start_time": "2024-12-09T00:47:09.830354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用 TF-IDF 將文本轉為數值特徵\n",
    "tfidf = TfidfVectorizer(max_features=1000)  # 選擇前 1000 個最常見詞語\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08df1159",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:47:28.655872Z",
     "iopub.status.busy": "2024-12-09T00:47:28.655470Z",
     "iopub.status.idle": "2024-12-09T00:56:18.119852Z",
     "shell.execute_reply": "2024-12-09T00:56:18.118528Z"
    },
    "papermill": {
     "duration": 529.476468,
     "end_time": "2024-12-09T00:56:18.127060",
     "exception": false,
     "start_time": "2024-12-09T00:47:28.650592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.67      0.05      0.10     39867\n",
      "anticipation       0.50      0.38      0.43    248935\n",
      "     disgust       0.32      0.14      0.20    139101\n",
      "        fear       0.64      0.16      0.26     63999\n",
      "         joy       0.43      0.83      0.57    516017\n",
      "     sadness       0.35      0.27      0.30    193437\n",
      "    surprise       0.48      0.06      0.10     48729\n",
      "       trust       0.50      0.12      0.19    205478\n",
      "\n",
      "    accuracy                           0.43   1455563\n",
      "   macro avg       0.49      0.25      0.27   1455563\n",
      "weighted avg       0.45      0.43      0.38   1455563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 訓練邏輯回歸模型\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 預測結果\n",
    "y_pred = model.predict(X_train_tfidf)\n",
    "\n",
    "# 評估模型\n",
    "print(classification_report(y_train, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "686b3327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:56:18.136872Z",
     "iopub.status.busy": "2024-12-09T00:56:18.136111Z",
     "iopub.status.idle": "2024-12-09T00:56:18.760066Z",
     "shell.execute_reply": "2024-12-09T00:56:18.758689Z"
    },
    "papermill": {
     "duration": 0.631175,
     "end_time": "2024-12-09T00:56:18.762384",
     "exception": false,
     "start_time": "2024-12-09T00:56:18.131209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file generated: /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# 預測情緒\n",
    "test_data.loc[:, 'emotion'] = model.predict(X_test_tfidf)  # 使用 .loc 修改資料\n",
    "\n",
    "# 生成提交文件\n",
    "submission = test_data[['tweet_id', 'emotion']].copy()\n",
    "submission.columns = ['id', 'emotion']\n",
    "\n",
    "\n",
    "\n",
    "# 保存到 /kaggle/working 目錄\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"Submission file generated: /kaggle/working/submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9912598,
     "sourceId": 87232,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 753.176903,
   "end_time": "2024-12-09T00:56:22.189785",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-09T00:43:49.012882",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
