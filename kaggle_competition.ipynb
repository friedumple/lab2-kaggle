{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fab584e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-09T00:43:51.938351Z",
     "iopub.status.busy": "2024-12-09T00:43:51.937962Z",
     "iopub.status.idle": "2024-12-09T00:44:31.490953Z",
     "shell.execute_reply": "2024-12-09T00:44:31.489687Z"
    },
    "papermill": {
     "duration": 39.56235,
     "end_time": "2024-12-09T00:44:31.495735",
     "exception": false,
     "start_time": "2024-12-09T00:43:51.933385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _score          _index                                            _source  \\\n",
      "0     391  hashtag_tweets  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...   \n",
      "1     433  hashtag_tweets  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...   \n",
      "2     232  hashtag_tweets  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...   \n",
      "3     376  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...   \n",
      "4     989  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...   \n",
      "\n",
      "            _crawldate   _type  \n",
      "0  2015-05-23 11:42:47  tweets  \n",
      "1  2016-01-28 04:52:09  tweets  \n",
      "2  2017-12-25 04:39:20  tweets  \n",
      "3  2016-01-24 23:53:05  tweets  \n",
      "4  2016-01-08 17:18:59  tweets  \n",
      "   tweet_id       emotion\n",
      "0  0x3140b1       sadness\n",
      "1  0x368b73       disgust\n",
      "2  0x296183  anticipation\n",
      "3  0x2bd6e1           joy\n",
      "4  0x2ee1dd  anticipation\n",
      "   tweet_id identification\n",
      "0  0x28cc61           test\n",
      "1  0x29e452          train\n",
      "2  0x2b3819          train\n",
      "3  0x2db41f           test\n",
      "4  0x2a2acc          train\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# è®€å–æ•¸æ“š\n",
    "tweets = pd.read_json('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', lines=True)\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv')\n",
    "data_id = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv')\n",
    "\n",
    "# æª¢æŸ¥æ•¸æ“š\n",
    "print(tweets.head())\n",
    "print(emotion.head())\n",
    "print(data_id.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "835ca688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:44:31.503020Z",
     "iopub.status.busy": "2024-12-09T00:44:31.502649Z",
     "iopub.status.idle": "2024-12-09T00:44:35.770297Z",
     "shell.execute_reply": "2024-12-09T00:44:35.769067Z"
    },
    "papermill": {
     "duration": 4.274577,
     "end_time": "2024-12-09T00:44:35.773168",
     "exception": false,
     "start_time": "2024-12-09T00:44:31.498591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in tweets: Index(['_score', '_index', '_source', '_crawldate', '_type'], dtype='object')\n",
      "Columns in emotion: Index(['tweet_id', 'emotion'], dtype='object')\n",
      "Columns in data_id: Index(['tweet_id', 'identification'], dtype='object')\n",
      "   tweet_id       emotion\n",
      "0  0x3140b1       sadness\n",
      "1  0x368b73       disgust\n",
      "2  0x296183  anticipation\n",
      "3  0x2bd6e1           joy\n",
      "4  0x2ee1dd  anticipation\n",
      "   tweet_id identification\n",
      "0  0x28cc61           test\n",
      "1  0x29e452          train\n",
      "2  0x2b3819          train\n",
      "3  0x2db41f           test\n",
      "4  0x2a2acc          train\n"
     ]
    }
   ],
   "source": [
    "# æª¢æŸ¥ tweets çš„åˆ—\n",
    "print(\"Columns in tweets:\", tweets.columns)\n",
    "\n",
    "# æª¢æŸ¥ emotion çš„åˆ—\n",
    "print(\"Columns in emotion:\", emotion.columns)\n",
    "\n",
    "# æª¢æŸ¥ data_id çš„åˆ—\n",
    "print(\"Columns in data_id:\", data_id.columns)\n",
    "\n",
    "# ç¢ºä¿æ‰€æœ‰è¡¨çš„ 'tweet_id' åˆ—åä¸€è‡´\n",
    "tweets.rename(columns=lambda x: x.strip(), inplace=True)  # å»é™¤ç©ºæ ¼\n",
    "emotion.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data_id.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "# å¦‚æœæœ‰å…·é«”åˆ—åéŒ¯èª¤ï¼Œä¾‹å¦‚ 'Tweet_ID' æˆ– 'tweetId'\n",
    "tweets.rename(columns={'Tweet_ID': 'tweet_id'}, inplace=True)\n",
    "emotion.rename(columns={'Tweet_ID': 'tweet_id'}, inplace=True)\n",
    "data_id.rename(columns={'Tweet_ID': 'tweet_id'}, inplace=True)\n",
    "\n",
    "# æª¢æŸ¥æ–‡ä»¶é ­éƒ¨æ˜¯å¦æ­£ç¢º\n",
    "print(pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv').head())\n",
    "print(pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv').head())\n",
    "\n",
    "# ç¢ºä¿æ–‡ä»¶è®€å–æ™‚æ­£ç¢ºè™•ç†ç·¨ç¢¼\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv', encoding='utf-8')\n",
    "data_id = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80cd470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:44:35.780817Z",
     "iopub.status.busy": "2024-12-09T00:44:35.780465Z",
     "iopub.status.idle": "2024-12-09T00:45:46.544716Z",
     "shell.execute_reply": "2024-12-09T00:45:46.543638Z"
    },
    "papermill": {
     "duration": 70.770981,
     "end_time": "2024-12-09T00:45:46.547238",
     "exception": false,
     "start_time": "2024-12-09T00:44:35.776257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_score': 391, '_index': 'hashtag_tweets', '_source': {'tweet': {'hashtags': ['Snapchat'], 'tweet_id': '0x376b20', 'text': 'People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that\\'s <LH>'}}, '_crawldate': '2015-05-23 11:42:47', '_type': 'tweets'}\n",
      "{'_score': 433, '_index': 'hashtag_tweets', '_source': {'tweet': {'hashtags': ['freepress', 'TrumpLegacy', 'CNN'], 'tweet_id': '0x2d5350', 'text': '@brianklaas As we see, Trump is dangerous to #freepress around the world. What a <LH> <LH> #TrumpLegacy.  #CNN'}}, '_crawldate': '2016-01-28 04:52:09', '_type': 'tweets'}\n",
      "{'_score': 232, '_index': 'hashtag_tweets', '_source': {'tweet': {'hashtags': ['bibleverse'], 'tweet_id': '0x28b412', 'text': 'Confident of your obedience, I write to you, knowing that you will do even more than I ask. (Philemon 1:21) 3/4 #bibleverse <LH> <LH>'}}, '_crawldate': '2017-12-25 04:39:20', '_type': 'tweets'}\n",
      "{'_score': 376, '_index': 'hashtag_tweets', '_source': {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5b0', 'text': 'Now ISSA is stalking Tasha ğŸ˜‚ğŸ˜‚ğŸ˜‚ <LH>'}}, '_crawldate': '2016-01-24 23:53:05', '_type': 'tweets'}\n",
      "{'_score': 989, '_index': 'hashtag_tweets', '_source': {'tweet': {'hashtags': [], 'tweet_id': '0x2de201', 'text': '\"Trust is not the same as faith. A friend is someone you trust. Putting faith in anyone is a mistake.\" ~ Christopher Hitchens <LH> <LH>'}}, '_crawldate': '2016-01-08 17:18:59', '_type': 'tweets'}\n",
      "Flattened tweets data preview:\n",
      "                  tweet.hashtags tweet.tweet_id  \\\n",
      "0                     [Snapchat]       0x376b20   \n",
      "1  [freepress, TrumpLegacy, CNN]       0x2d5350   \n",
      "2                   [bibleverse]       0x28b412   \n",
      "3                             []       0x1cd5b0   \n",
      "4                             []       0x2de201   \n",
      "\n",
      "                                          tweet.text  \n",
      "0  People who post \"add me on #Snapchat\" must be ...  \n",
      "1  @brianklaas As we see, Trump is dangerous to #...  \n",
      "2  Confident of your obedience, I write to you, k...  \n",
      "3                Now ISSA is stalking Tasha ğŸ˜‚ğŸ˜‚ğŸ˜‚ <LH>  \n",
      "4  \"Trust is not the same as faith. A friend is s...  \n",
      "Merged data preview:\n",
      "                  tweet.hashtags  tweet_id  \\\n",
      "0                     [Snapchat]  0x376b20   \n",
      "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
      "2                   [bibleverse]  0x28b412   \n",
      "3                             []  0x1cd5b0   \n",
      "4                             []  0x2de201   \n",
      "\n",
      "                                          tweet_text       emotion  \\\n",
      "0  People who post \"add me on #Snapchat\" must be ...  anticipation   \n",
      "1  @brianklaas As we see, Trump is dangerous to #...       sadness   \n",
      "2  Confident of your obedience, I write to you, k...           NaN   \n",
      "3                Now ISSA is stalking Tasha ğŸ˜‚ğŸ˜‚ğŸ˜‚ <LH>          fear   \n",
      "4  \"Trust is not the same as faith. A friend is s...           NaN   \n",
      "\n",
      "  identification  \n",
      "0          train  \n",
      "1          train  \n",
      "2           test  \n",
      "3          train  \n",
      "4           test  \n"
     ]
    }
   ],
   "source": [
    "# åŒ¯å…¥å¿…è¦å¥—ä»¶\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# è®€å– JSON æª”æ¡ˆä¸¦æª¢æŸ¥çµæ§‹\n",
    "tweets = []\n",
    "with open('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i < 5:  # æª¢æŸ¥å‰ 5 è¡Œçš„ JSON çµæ§‹\n",
    "            print(json.loads(line))  # æ‰“å° JSON çµæ§‹\n",
    "        tweets.append(json.loads(line))\n",
    "\n",
    "# å°‡ JSON è³‡æ–™è½‰ç‚º DataFrame\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "\n",
    "# æå– `_source` ä¸­çš„ `tweet` è³‡æ–™\n",
    "tweets_df = pd.json_normalize(tweets_df['_source'])\n",
    "\n",
    "# æª¢æŸ¥å±•å¹³å¾Œçš„è³‡æ–™\n",
    "print(\"Flattened tweets data preview:\")\n",
    "print(tweets_df.head())\n",
    "\n",
    "# é‡å‘½ååˆ—ä»¥åŒ¹é…å…¶ä»–è¡¨æ ¼\n",
    "tweets_df.rename(columns={'tweet.tweet_id': 'tweet_id', 'tweet.text': 'tweet_text'}, inplace=True)\n",
    "\n",
    "# è®€å–å…¶ä»–è³‡æ–™è¡¨\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv', encoding='utf-8')\n",
    "data_id = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv', encoding='utf-8')\n",
    "\n",
    "# æª¢æŸ¥æ¬„ä½åç¨±ä¸¦å»é™¤å¤šé¤˜ç©ºæ ¼\n",
    "tweets_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "emotion.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data_id.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "# åˆä½µè³‡æ–™\n",
    "tweets_df = tweets_df.merge(emotion, on='tweet_id', how='left')  # åˆä½µæƒ…ç·’æ¨™ç±¤\n",
    "tweets_df = tweets_df.merge(data_id, on='tweet_id', how='left')  # åˆä½µæ•¸æ“šè­˜åˆ¥\n",
    "\n",
    "# ç¢ºèªçµæœ\n",
    "print(\"Merged data preview:\")\n",
    "print(tweets_df.head())\n",
    "\n",
    "# å„²å­˜çµæœåˆ° CSVï¼ˆå¯é¸ï¼‰\n",
    "tweets_df.to_csv('merged_tweets.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142bd393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:45:46.555383Z",
     "iopub.status.busy": "2024-12-09T00:45:46.554969Z",
     "iopub.status.idle": "2024-12-09T00:47:09.824369Z",
     "shell.execute_reply": "2024-12-09T00:47:09.823163Z"
    },
    "papermill": {
     "duration": 83.276292,
     "end_time": "2024-12-09T00:47:09.826829",
     "exception": false,
     "start_time": "2024-12-09T00:45:46.550537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Columns: Index(['tweet.hashtags', 'tweet_id', 'tweet_text'], dtype='object')\n",
      "Training Data:                   tweet.hashtags  tweet_id  \\\n",
      "0                     [Snapchat]  0x376b20   \n",
      "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
      "3                             []  0x1cd5b0   \n",
      "5      [authentic, LaughOutLoud]  0x1d755c   \n",
      "6                             []  0x2c91a8   \n",
      "\n",
      "                                          tweet_text  \\\n",
      "0  People who post \"add me on #Snapchat\" must be ...   \n",
      "1  @brianklaas As we see, Trump is dangerous to #...   \n",
      "3                Now ISSA is stalking Tasha ğŸ˜‚ğŸ˜‚ğŸ˜‚ <LH>   \n",
      "5  @RISKshow @TheKevinAllison Thx for the BEST TI...   \n",
      "6       Still waiting on those supplies Liscus. <LH>   \n",
      "\n",
      "                                          clean_text       emotion  \\\n",
      "0   people post add must dehydrated cuz man thats lh  anticipation   \n",
      "1             see trump dangerous around world lh lh       sadness   \n",
      "3                             issa stalking tasha lh          fear   \n",
      "5  thx best time tonight stories heartbreakingly ...           joy   \n",
      "6                   still waiting supplies liscus lh  anticipation   \n",
      "\n",
      "  identification  \n",
      "0          train  \n",
      "1          train  \n",
      "3          train  \n",
      "5          train  \n",
      "6          train  \n",
      "Test Data:                        tweet.hashtags  tweet_id  \\\n",
      "2                        [bibleverse]  0x28b412   \n",
      "4                                  []  0x2de201   \n",
      "9   [materialism, money, possessions]  0x218443   \n",
      "30               [GodsPlan, GodsWork]  0x2939d5   \n",
      "33                                 []  0x26289a   \n",
      "\n",
      "                                           tweet_text  \\\n",
      "2   Confident of your obedience, I write to you, k...   \n",
      "4   \"Trust is not the same as faith. A friend is s...   \n",
      "9   When do you have enough ? When are you satisfi...   \n",
      "30  God woke you up, now chase the day #GodsPlan #...   \n",
      "33  In these tough times, who do YOU turn to as yo...   \n",
      "\n",
      "                                           clean_text emotion identification  \n",
      "2   confident obedience write knowing even ask phi...     NaN           test  \n",
      "4   trust faith friend someone trust putting faith...     NaN           test  \n",
      "9               enough satisfied goal really money lh     NaN           test  \n",
      "30                              god woke chase day lh     NaN           test  \n",
      "33                    tough times turn symbol hope lh     NaN           test  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# ç¢ºä¿ä¸‹è¼‰ nltk åœç”¨è©ï¼ˆå¦‚æœç„¡æ³•åœ¨ç·šä¸‹è¼‰ï¼Œæä¾›æ‰‹å‹•è·¯å¾‘ï¼‰\n",
    "try:\n",
    "    nltk.download('stopwords')\n",
    "except:\n",
    "    print(\"Unable to download stopwords. Please check the network connection.\")\n",
    "\n",
    "# å¦‚æœç¶²è·¯ä¸å¯ç”¨ï¼Œæ‰‹å‹•æä¾›åœç”¨è©\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except:\n",
    "    stop_words = {\"a\", \"an\", \"the\", \"is\", \"in\", \"at\", \"of\", \"on\", \"and\", \"to\", \"with\", \"for\", \"by\", \"that\", \"this\", \"from\"}\n",
    "\n",
    "# ç¢ºä¿ `tweets` æ˜¯ DataFrame\n",
    "tweets_list = []  # å¦‚æœåŸæœ¬æ˜¯ list, æ‡‰å…ˆæ§‹é€  DataFrame\n",
    "with open('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        tweets_list.append(json.loads(line))\n",
    "\n",
    "# å°‡ JSON list è½‰ç‚º DataFrame\n",
    "tweets_df = pd.json_normalize([tweet['_source'] for tweet in tweets_list])\n",
    "\n",
    "# æå–æ¬„ä½\n",
    "tweets_df.rename(columns={'tweet.text': 'tweet_text', 'tweet.tweet_id': 'tweet_id'}, inplace=True)\n",
    "\n",
    "# ç¢ºèªæ¬„ä½\n",
    "print(\"Columns:\", tweets_df.columns)\n",
    "\n",
    "# é è™•ç†å‡½æ•¸\n",
    "def preprocess_text(text):\n",
    "    # åˆªé™¤ç¶²å€ã€æ¨™ç±¤å’Œç‰¹æ®Šå­—ç¬¦\n",
    "    text = re.sub(r'http\\S+|www\\S+|@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()  # å…¨éƒ¨è½‰å°å¯«\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # ç§»é™¤åœç”¨è©\n",
    "    return text\n",
    "\n",
    "# é è™•ç†æ–‡æœ¬\n",
    "tweets_df['clean_text'] = tweets_df['tweet_text'].apply(preprocess_text)\n",
    "\n",
    "# åŠ è¼‰å…¶ä»–è¡¨æ ¼\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv', encoding='utf-8')\n",
    "data_id = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv', encoding='utf-8')\n",
    "\n",
    "# åˆä½µæ•¸æ“š\n",
    "tweets_df = tweets_df.merge(emotion, on='tweet_id', how='left')\n",
    "tweets_df = tweets_df.merge(data_id, on='tweet_id', how='left')\n",
    "\n",
    "# åˆ†å‰²è¨“ç·´å’Œæ¸¬è©¦æ•¸æ“š\n",
    "train_data = tweets_df[tweets_df['identification'] == 'train']\n",
    "test_data = tweets_df[tweets_df['identification'] == 'test']\n",
    "\n",
    "X_train = train_data['clean_text']\n",
    "y_train = train_data['emotion']\n",
    "X_test = test_data['clean_text']\n",
    "\n",
    "# ç¢ºèªåˆ†å‰²å¾Œæ•¸æ“š\n",
    "print(\"Training Data:\", train_data.head())\n",
    "print(\"Test Data:\", test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c755c401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:47:09.835482Z",
     "iopub.status.busy": "2024-12-09T00:47:09.835047Z",
     "iopub.status.idle": "2024-12-09T00:47:28.644602Z",
     "shell.execute_reply": "2024-12-09T00:47:28.643471Z"
    },
    "papermill": {
     "duration": 18.816719,
     "end_time": "2024-12-09T00:47:28.647073",
     "exception": false,
     "start_time": "2024-12-09T00:47:09.830354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ TF-IDF å°‡æ–‡æœ¬è½‰ç‚ºæ•¸å€¼ç‰¹å¾µ\n",
    "tfidf = TfidfVectorizer(max_features=1000)  # é¸æ“‡å‰ 1000 å€‹æœ€å¸¸è¦‹è©èª\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08df1159",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:47:28.655872Z",
     "iopub.status.busy": "2024-12-09T00:47:28.655470Z",
     "iopub.status.idle": "2024-12-09T00:56:18.119852Z",
     "shell.execute_reply": "2024-12-09T00:56:18.118528Z"
    },
    "papermill": {
     "duration": 529.476468,
     "end_time": "2024-12-09T00:56:18.127060",
     "exception": false,
     "start_time": "2024-12-09T00:47:28.650592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.67      0.05      0.10     39867\n",
      "anticipation       0.50      0.38      0.43    248935\n",
      "     disgust       0.32      0.14      0.20    139101\n",
      "        fear       0.64      0.16      0.26     63999\n",
      "         joy       0.43      0.83      0.57    516017\n",
      "     sadness       0.35      0.27      0.30    193437\n",
      "    surprise       0.48      0.06      0.10     48729\n",
      "       trust       0.50      0.12      0.19    205478\n",
      "\n",
      "    accuracy                           0.43   1455563\n",
      "   macro avg       0.49      0.25      0.27   1455563\n",
      "weighted avg       0.45      0.43      0.38   1455563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# è¨“ç·´é‚è¼¯å›æ­¸æ¨¡å‹\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# é æ¸¬çµæœ\n",
    "y_pred = model.predict(X_train_tfidf)\n",
    "\n",
    "# è©•ä¼°æ¨¡å‹\n",
    "print(classification_report(y_train, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "686b3327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T00:56:18.136872Z",
     "iopub.status.busy": "2024-12-09T00:56:18.136111Z",
     "iopub.status.idle": "2024-12-09T00:56:18.760066Z",
     "shell.execute_reply": "2024-12-09T00:56:18.758689Z"
    },
    "papermill": {
     "duration": 0.631175,
     "end_time": "2024-12-09T00:56:18.762384",
     "exception": false,
     "start_time": "2024-12-09T00:56:18.131209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file generated: /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# é æ¸¬æƒ…ç·’\n",
    "test_data.loc[:, 'emotion'] = model.predict(X_test_tfidf)  # ä½¿ç”¨ .loc ä¿®æ”¹è³‡æ–™\n",
    "\n",
    "# ç”Ÿæˆæäº¤æ–‡ä»¶\n",
    "submission = test_data[['tweet_id', 'emotion']].copy()\n",
    "submission.columns = ['id', 'emotion']\n",
    "\n",
    "\n",
    "\n",
    "# ä¿å­˜åˆ° /kaggle/working ç›®éŒ„\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"Submission file generated: /kaggle/working/submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9912598,
     "sourceId": 87232,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 753.176903,
   "end_time": "2024-12-09T00:56:22.189785",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-09T00:43:49.012882",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
